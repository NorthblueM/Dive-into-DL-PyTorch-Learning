# 《动手学深度学习》PyTorch版学习归纳总结
## 任何模型的基本要素
* 模型
* 数据集
* 损失函数
* 优化函数
* 模型评价

## 模型
- 线性回归模型：单层线性神经网络
- softmax回归模型：分类，将输出值变换成值为正且和为1的概率分布：
- 多层感知机（multilayer perceptron，MLP）：含有至少一个隐藏层的由全连接层组成的神经网络，且每个隐藏层的输出通过激活函数进行变换。

## 损失函数
+ 均方误差损失函数
+ 交叉熵损失函数：衡量两个概率分布差异的测量函数

## 优化方法
- 随机梯度下降：小批量随机梯度下降（mini-batch stochastic gradient descent）

## 模型评价方法
+ 分类准确率
+ 模型精度和计算效率

## 一些参数
* 批量大小：batch_size
* 学习率：lr
* 训练周期：epoch

## 程序流程
1. 生成数据集
2. 读取数据集
3. 定义模型
4. 初始化模型参数
5. 定义损失函数
6. 定义优化函数
7. 训练
8. 模型评价

## 激活函数
* ReLu
* sigmoid
* tanh  
关于激活函数的选择
ReLu函数是一个通用的激活函数，目前在大多数情况下使用。但是，ReLU函数只能在隐藏层中使用。
用于分类器时，sigmoid函数及其组合通常效果更好。由于梯度消失问题，有时要避免使用sigmoid和tanh函数。
在神经网络层数较多的时候，最好使用ReLu函数，ReLu函数比较简单计算量少，而sigmoid和tanh函数计算量大很多。
在选择激活函数的时候可以先选用ReLu函数如果效果不理想可以尝试其他激活函数。

## 文本预处理步骤
* 读入文本
* 分词
* 建立字典，将每个词映射到一个唯一的索引（index）
* 将文本从词的序列转换为索引的序列，方便输入模型

## 语言模型
* 作用：一段自然语言文本可以看作是一个离散时间序列，给定一个长度为T的词的序列(w1,w2,…,wT)，语言模型的目标就是评估该序列是否合理，即计算该序列的概率
### 基于统计的语言模型，主要是n元语法（n-gram）
* 词的概率可以通过该词在训练数据集中的相对词频来计算
* 马尔科夫假设是指一个词的出现只与前面n个词相关，即n阶马尔可夫链（Markov chain of order n）
* n元语法（n-grams），它是基于n−1阶马尔可夫链的概率语言模型
* n的取值：当n较小时，n元语法往往并不准确。例如，在一元语法中，由三个词组成的句子“你走先”和“你先走”的概率是一样的。然而，当n较大时，n元语法需要计算并存储大量的词频和多词相邻频率。
* 缺陷：1.参数空间过大，2.数据稀疏
* 程序流程：读取数据集，建立字符索引，时序数据的采样（参数：批量大小batch_size和时间步数n）：随机采样和相邻采样，
### 基于神经网络的语言模型



